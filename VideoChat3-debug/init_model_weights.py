#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VideoChat3æ¨¡å‹æƒé‡åˆå§‹åŒ–è„šæœ¬

ä½¿ç”¨æ–¹æ³•ï¼š
python init_model_weights.py

è¯¥è„šæœ¬ä¼šï¼š
1. ä»ViT-SO-400MåŠ è½½visionæƒé‡
2. ä»Qwen3-4B-Instruct-2507åŠ è½½languageæƒé‡  
3. åˆ›å»ºå®Œæ•´çš„VideoChat3æ¨¡å‹å¹¶ä¿å­˜
"""

import os
import sys
import json
import torch
from pathlib import Path
from transformers import AutoModel, AutoConfig
from safetensors import safe_open

# å¯¼å…¥VideoChat3ç›¸å…³æ¨¡å—
from configuration_videochat3 import VideoChat3Config
from modeling_videochat3 import VideoChat3ForConditionalGeneration


def load_weights_from_safetensors(model_path: str):
    """ä»safetensorsæ–‡ä»¶åŠ è½½æƒé‡"""
    weights = {}
    
    # æ£€æŸ¥å•ä¸ªsafetensorsæ–‡ä»¶
    single_file = os.path.join(model_path, "model.safetensors")
    if os.path.exists(single_file):
        print(f"åŠ è½½å•ä¸ªæƒé‡æ–‡ä»¶: {single_file}")
        with safe_open(single_file, framework="pt", device="cpu") as f:
            for key in f.keys():
                weights[key] = f.get_tensor(key)
        return weights
    
    # æ£€æŸ¥å¤šä¸ªsafetensorsæ–‡ä»¶
    index_file = os.path.join(model_path, "model.safetensors.index.json")
    if os.path.exists(index_file):
        print(f"åŠ è½½å¤šä¸ªæƒé‡æ–‡ä»¶ï¼Œç´¢å¼•: {index_file}")
        with open(index_file, 'r') as f:
            index_data = json.load(f)
        
        for weight_file in index_data["weight_map"].values():
            file_path = os.path.join(model_path, weight_file)
            if os.path.exists(file_path):
                with safe_open(file_path, framework="pt", device="cpu") as f:
                    for key in f.keys():
                        weights[key] = f.get_tensor(key)
        return weights
    
    raise FileNotFoundError(f"æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶åœ¨: {model_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("VideoChat3æ¨¡å‹æƒé‡åˆå§‹åŒ–")
    print("=" * 40)
    
    # è®¾ç½®è·¯å¾„
    vit_path = "ViT-SO-400M"
    qwen3_path = "Qwen3-4B-Instruct-2507"
    current_dir = ""
    output_path = os.path.join(current_dir, "initialized_model")
    
    try:
        # 1. æ£€æŸ¥è¾“å…¥è·¯å¾„
        print("æ£€æŸ¥è¾“å…¥è·¯å¾„...")
        if not os.path.exists(vit_path):
            raise FileNotFoundError(f"MoonViTè·¯å¾„ä¸å­˜åœ¨: {vit_path}")
        if not os.path.exists(qwen3_path):
            raise FileNotFoundError(f"Qwen3è·¯å¾„ä¸å­˜åœ¨: {qwen3_path}")
        print("âœ… è¾“å…¥è·¯å¾„æ£€æŸ¥é€šè¿‡")
        
        # 2. åŠ è½½é…ç½®
        print("\nåŠ è½½VideoChat3é…ç½®...")
        config_path = os.path.join(current_dir, "config.json")
        with open(config_path, 'r') as f:
            config_dict = json.load(f)
        config = VideoChat3Config.from_dict(config_dict)
        print("âœ… é…ç½®åŠ è½½å®Œæˆ")
        
        # 3. åˆ›å»ºæ¨¡å‹
        print("\nåˆ›å»ºVideoChat3æ¨¡å‹...")
        model = VideoChat3ForConditionalGeneration(config)
        print("âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ")
        
        # 4. åŠ è½½é¢„è®­ç»ƒæƒé‡
        print("\nåŠ è½½é¢„è®­ç»ƒæƒé‡...")
        
        # åŠ è½½MoonViTæƒé‡
        print("  åŠ è½½MoonViTæƒé‡...")
        vit_weights = load_weights_from_safetensors(vit_path)
        print(f"  âœ… åŠ è½½äº† {len(vit_weights)} ä¸ªMoonViTæƒé‡")
        
        # åŠ è½½Qwen3æƒé‡
        print("  åŠ è½½Qwen3æƒé‡...")
        qwen3_weights = load_weights_from_safetensors(qwen3_path)
        print(f"  âœ… åŠ è½½äº† {len(qwen3_weights)} ä¸ªQwen3æƒé‡")
        
        # 5. æ„å»ºå®Œæ•´çš„çŠ¶æ€å­—å…¸
        print("\næ„å»ºæ¨¡å‹çŠ¶æ€å­—å…¸...")
        state_dict = {}
        
        # æ·»åŠ Visionæƒé‡
        for key, tensor in vit_weights.items():
            state_dict[f"model.vision_tower.{key}"] = tensor
        
        # æ·»åŠ Languageæƒé‡
        for key, tensor in qwen3_weights.items():
            state_dict[f"model.language_model.{key}"] = tensor
        
        print(f"âœ… çŠ¶æ€å­—å…¸æ„å»ºå®Œæˆï¼Œå…± {len(state_dict)} ä¸ªæƒé‡")
        
        # 6. åŠ è½½æƒé‡åˆ°æ¨¡å‹
        print("\nåŠ è½½æƒé‡åˆ°æ¨¡å‹...")
        missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)
        
        if missing_keys:
            print(f"âš ï¸  ç¼ºå¤± {len(missing_keys)} ä¸ªæƒé‡ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºæœ‰äº›æƒé‡éœ€è¦é»˜è®¤åˆå§‹åŒ–ï¼‰")
        
        if unexpected_keys:
            print(f"âš ï¸  æœªä½¿ç”¨ {len(unexpected_keys)} ä¸ªæƒé‡")
        
        print("âœ… æƒé‡åŠ è½½å®Œæˆ")
        
        # 7. æµ‹è¯•æ¨¡å‹
        print("\næµ‹è¯•æ¨¡å‹...")
        model.eval()
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        batch_size = 1
        seq_len = 5
        vocab_size = model.config.text_config.vocab_size
        
        input_ids = torch.randint(0, min(vocab_size, 1000), (batch_size, seq_len))
        
        with torch.no_grad():
            outputs = model(input_ids=input_ids)
            print(f"âœ… æ¨¡å‹æµ‹è¯•æˆåŠŸ! è¾“å‡ºå½¢çŠ¶: {outputs.logits.shape}")
        
        # 8. ä¿å­˜æ¨¡å‹
        print(f"\nä¿å­˜æ¨¡å‹åˆ°: {output_path}")
        os.makedirs(output_path, exist_ok=True)
        model.save_pretrained(output_path)
        print("âœ… æ¨¡å‹ä¿å­˜å®Œæˆ")
        
        # 9. æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        print("\n" + "=" * 40)
        print("ğŸ‰ VideoChat3æ¨¡å‹åˆå§‹åŒ–å®Œæˆ!")
        print(f"ğŸ“ æ¨¡å‹ä¿å­˜ä½ç½®: {output_path}")
        print(f"ğŸ“Š æ¨¡å‹é…ç½®:")
        print(f"   - Visionæ¨¡å‹: {config.vision_config.model_type}")
        print(f"   - Textæ¨¡å‹: {config.text_config.model_type}")
        print(f"   - æ€»å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    if not success:
        sys.exit(1)
